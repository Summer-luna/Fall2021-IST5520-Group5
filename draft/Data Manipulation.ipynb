{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b4bdfb",
   "metadata": {},
   "source": [
    "<h2>Data Manipulation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24a804",
   "metadata": {},
   "source": [
    "In order to start the data analysis, we will need to import a variety of packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1faf8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8354f20",
   "metadata": {},
   "source": [
    "We will read in the data, which was downloaded from the Airbnb website and look at its info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8ec796",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datas/listings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l4/02h672sn7w56vdlzj5gtgwzc0000gn/T/ipykernel_39733/2500275054.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datas/listings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datas/listings.csv'"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "dat = pd.read_csv('datas/listings.csv')\n",
    "dat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba48da2",
   "metadata": {},
   "source": [
    "We can see that there are 74 columns, and 6,366 observations, however some values are missing in various columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3243a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dat['calendar_last_scraped'] == dat['last_scraped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6445d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb15a6d",
   "metadata": {},
   "source": [
    "<h2>Data Cleansing</h2>\n",
    "\n",
    "<h4>Drop off irrelevant columns and drop off reasons :</h4>\n",
    "\n",
    "* URLs will not be useful\n",
    "* Empty columns: **'neighborhood_group_cleansed'**, **'bathrooms'**, **'calendar_updated'**\n",
    "* **'neighborhood'** column only has blank values or **'Chicago, Illinois, United States'** value, making it useless\n",
    "* Drop **'host_listings_count'** and **'host_total_listings_count'**, use the calculated_host_listings columns, because values are the same.\n",
    "* **'scrape_id'** is all the same value and not useful for our needs\n",
    "* **'calendar_last_scraped'** can be dropped (same value as **'last_scraped'**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.drop(['scrape_id','listing_url','host_url','host_thumbnail_url','host_picture_url','picture_url',\n",
    "               'neighbourhood_group_cleansed','bathrooms','calendar_updated','neighbourhood',\n",
    "               'calendar_last_scraped','host_listings_count','host_total_listings_count'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89528a5a",
   "metadata": {},
   "source": [
    "<h4>Bathrooms Column:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.rename(columns={'id':'property_id', 'bathrooms_text':'bathrooms'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['bathrooms'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be853d",
   "metadata": {},
   "source": [
    "Looking at the 'bathrooms_text' column, we see that it is not very usable in its current state.  We will split the bathroom text column into two: one containing a float variable for the number of bathrooms, and the other an additional descriptor of the bathroom (shared/private)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b003bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let us make all text lowercase to simplify string manipulation\n",
    "# dat['bathrooms'] = dat['bathrooms'].str.lower()\n",
    "\n",
    "# Next we must convert any text 'half' to 0.5 so it is included in the subsequent number extraction\n",
    "#dat['bathrooms'] = dat['bathrooms'].str.replace(r'(half)+','0.5', regex = True)\n",
    "\n",
    "# Then extract the numbers into the new 'bathrooms' float32 data type column\n",
    "#dat['bathrooms'] = dat['bathrooms'].str.extract(r'(\\d+\\.?\\d*)', expand = True).astype(np.float32)\n",
    "\n",
    "# This leaves us with only float and NaN values\n",
    "#dat['bathrooms'].unique()\n",
    "# First let us split the text by white space\n",
    "bath = dat['bathrooms'].str.split(' ', expand = True)\n",
    "bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then drop column 1 and 2, keep column 0\n",
    "bath = bath.drop([1,2], axis=1)\n",
    "dat['bathrooms'] = bath[0].replace(['Private', 'Shared', 'Half-bath'], '0.5')\n",
    "dat['bathrooms'] = dat['bathrooms'].astype('float')\n",
    "dat['bathrooms'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5825260f",
   "metadata": {},
   "source": [
    "Above are the unique values left for the float variable in the column 'bathrooms'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7befd71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8071219d",
   "metadata": {},
   "source": [
    "This leaves us with only 1,587 observations with one of the bathroom descriptors, 'shared' or 'private'; the rest are missing values since the original data did not contain text for them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8817c",
   "metadata": {},
   "source": [
    "<h4>DateTime Columns:</h4>\n",
    "\n",
    "Next, let's convert the datetime columns into the proper datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76914b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime data type\n",
    "for x in ['last_scraped', 'host_since', 'first_review', 'last_review']:\n",
    "    dat[x] = pd.to_datetime(dat[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214641a9",
   "metadata": {},
   "source": [
    "**Create a new column to get how long the host exist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d420d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_period'] = dat['last_scraped'] - dat['host_since']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63a979",
   "metadata": {},
   "source": [
    "<h4>Rate Columns:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_response_rate'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53201228",
   "metadata": {},
   "source": [
    "We can see that we will need to convert the percentage columns ('host_response_rate' and 'host_acceptance_rate') into float variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca96f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert host response rate and acceptance rate columns into float\n",
    "\n",
    "dat['host_response_rate'] = dat['host_response_rate'].str.replace(r'(\\D)','', regex = True).astype(np.float32)/100\n",
    "dat['host_acceptance_rate'] = dat['host_acceptance_rate'].str.replace(r'(\\D)','', regex = True).astype(np.float32)/100\n",
    "dat['host_response_rate'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb596136",
   "metadata": {},
   "source": [
    "<h4>Boolean Columns:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_is_superhost'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84579ac9",
   "metadata": {},
   "source": [
    "We will convert the 't' and 'f' values to binary float values for later analysis, where 1 will mean \"True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41586694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map superhost column to boolean values\n",
    "def repl_f_t(l):\n",
    "    l = l.replace('f', 0)\n",
    "    l = l.replace('t', 1);\n",
    "    return l\n",
    "dat['host_is_superhost'] = repl_f_t(dat['host_is_superhost']).astype('float');\n",
    "dat['host_identity_verified'] = repl_f_t(dat['host_identity_verified']).astype('float')\n",
    "dat['instant_bookable'] = repl_f_t(dat['instant_bookable']).astype('float')\n",
    "dat['host_has_profile_pic'] = repl_f_t(dat['host_has_profile_pic']).astype('float')\n",
    "dat['has_availability'] = repl_f_t(dat['has_availability']).astype('float')\n",
    "\n",
    "#dat['host_is_superhost'] = dat['host_is_superhost'].map({'t':1,'f':0}).astype('float')\n",
    "#dat['host_has_profile_pic'] = dat['host_has_profile_pic'].map({'t':1,'f':0}).astype('float')\n",
    "#dat['host_identity_verified'] = dat['host_identity_verified'].map({'t':1,'f':0}).astype('float')\n",
    "#dat['has_availability'] = dat['has_availability'].map({'t':1,'f':0}).astype('float')\n",
    "#dat['instant_bookable'] = dat['instant_bookable'].map({'t':1,'f':0}).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_is_superhost']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7b617",
   "metadata": {},
   "source": [
    "<h4>Price Column:</h4>\n",
    "\n",
    "Convert the price column to a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ed1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['price'] = dat['price'].str.extract(r'(\\d+\\.\\d+)').astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf1094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat['price'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['license'].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91195b49",
   "metadata": {},
   "source": [
    "Convert license to binary value: 1 = host have license number, 0 = host do not have license number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dat = dat.drop(['license'], axis=1)\n",
    "dat['have_license'] = dat['license'].isnull()\n",
    "dat['have_license'] = dat['have_license'].map({False:1, True:0})\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa5f04",
   "metadata": {},
   "source": [
    "**Remove duplicate rows from dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeed7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a784e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.loc[:,~dat.columns.duplicated()]\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac3318",
   "metadata": {},
   "source": [
    "**Dummy Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(dat['host_is_superhost'])\n",
    "dat = pd.concat([dat,x], axis=1)\n",
    "dat = dat.rename(columns={0.0:'host_is_superhost_f', 1.0:'host_is_superhost_t'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0849793",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pd.get_dummies(dat['host_identity_verified'])\n",
    "dat = pd.concat([dat,x1], axis=1)\n",
    "dat = dat.rename(columns={0.0:'host_identity_verified_f', 1.0:'host_identity_verified_t'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = pd.get_dummies(dat['instant_bookable'])\n",
    "dat = pd.concat([dat,x2], axis=1)\n",
    "dat = dat.rename(columns={0.0:'instant_bookable_f', 1.0:'instant_bookable_t'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = pd.get_dummies(dat['host_has_profile_pic'])\n",
    "dat = pd.concat([dat,x2], axis=1)\n",
    "dat = dat.rename(columns={0.0:'host_has_profile_pic_f', 1.0:'host_has_profile_pic_t'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = pd.get_dummies(dat['has_availability'])\n",
    "dat = pd.concat([dat,x2], axis=1)\n",
    "dat = dat.rename(columns={0.0:'has_availability_f', 1.0:'has_availability_t'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2141aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.drop(['host_is_superhost_f', 'host_identity_verified_f', 'instant_bookable_f', 'host_has_profile_pic_f', 'has_availability_f'],axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7032fa",
   "metadata": {},
   "source": [
    "**Missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',100)\n",
    "dat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ddbddd",
   "metadata": {},
   "source": [
    "For columns: **'host_response_time'**, convert to binary value and create a new column represent if a host respose in a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_response_time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical within an hour,within a few hours, within a day to 1(true), NaN,a few days or more to 0(false) \n",
    "dat['host_response_inADay'] = dat.host_response_time.map({'within an hour': 1, \n",
    "                                                        'within a few hours': 1, \n",
    "                                                        'within a day':1, \n",
    "                                                        'a few days or more':0, \n",
    "                                                        np.nan:0})\n",
    "dat['host_response_inADay'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e689385f",
   "metadata": {},
   "source": [
    "For columns: **description**, **neighborhood_overview**, **host_location**, **host_about**, **host_neighbourhood**\n",
    "     using 'Unknown' to fill the missing value, because these columns does not have direct effect on project topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4073cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['description'].fillna(value='Unknown', inplace=True)\n",
    "\n",
    "dat['neighborhood_overview'].fillna(value='Unknown', inplace=True)\n",
    "\n",
    "dat['host_location'].fillna(value='Unknown', inplace=True)\n",
    "\n",
    "dat['host_about'].fillna(value='Unknown', inplace=True)\n",
    "\n",
    "dat['host_neighbourhood'].fillna(value='Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1680dcd",
   "metadata": {},
   "source": [
    "For columns: **host_name**, **host_since**, **host_has_profile_pic**, **host_identity_verified**, it is easy to see below these 10 rows contains many NaN value, so drop directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac309342",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[dat['host_name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.drop([dat.index[690], dat.index[744], dat.index[1541], dat.index[2705], dat.index[3189], dat.index[3240], dat.index[3630],\n",
    "                dat.index[3965], dat.index[4671], dat.index[5755]],inplace = True)\n",
    "dat.reset_index(drop=True, inplace=True)\n",
    "dat[dat['host_name'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d2d2a",
   "metadata": {},
   "source": [
    "For columns: **bedrooms** and **beds**, using mode to fill missing value, because fill with natural value to make the result less biased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e889b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['bedrooms'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['bedrooms'].fillna(value=1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['bedrooms'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f348cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['beds'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['beds'].fillna(value=1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7182ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['bedrooms'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb3d0f",
   "metadata": {},
   "source": [
    "For columns: **first_review**, **last_review**, **review_scores_rating**, **review_scores_accuracy**, **review_scores_cleanliness**, **review_scores_checkin**, **review_scores_communication**, **review_scores_location**, **review_scores_value**, **reviews_per_month**, most missing value caused by 'number_of_reviews'==0. So, fill those missing value with 0.0. Later review analysis process will exclude these rows since no number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100)\n",
    "dat[dat['number_of_reviews']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_review, last_review, will not be filled since no value suitable\n",
    "dat['review_scores_rating'].fillna(value=0.0, inplace=True)\n",
    "\n",
    "dat['review_scores_accuracy'].fillna(value=0.0, inplace=True)\n",
    "\n",
    "dat['review_scores_cleanliness'].fillna(value=0.0, inplace=True)\n",
    "\n",
    "dat['review_scores_checkin'].fillna(value=0.0, inplace=True)\n",
    "\n",
    "dat['review_scores_communication'].fillna(value=0.0, inplace=True)\n",
    "\n",
    "dat['review_scores_location'].fillna(value=0.0, inplace=True)\n",
    "\n",
    "dat['review_scores_value'].fillna(value=0.0, inplace=True)\n",
    "\n",
    "dat['reviews_per_month'].fillna(value=0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69966a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0f101",
   "metadata": {},
   "source": [
    "<h2>Data Exploration and Visualization</h2>\n",
    "\n",
    "Let us explore the data in the dataset.\n",
    "\n",
    "<h4>Unique Hosts</h4>\n",
    "\n",
    "First, how many unique hosts are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_by_host = dat['host_id'].value_counts()\n",
    "listings_by_host.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_by_host[listings_by_host > 1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9f13d",
   "metadata": {},
   "source": [
    "Here we can see that out of the 3,371 unique hosts, 799 have more than one listing in the Chicago area.  Interestingly, there is one host id with 260 listings.\n",
    "\n",
    "Let's graph this data to see the distribution of hosts with differing numbers of listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ae38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "p = sb.countplot(x=listings_by_host, order=sorted(listings_by_host.unique()))\n",
    "p.set_xticklabels(labels=p.get_xticklabels(),rotation=90)\n",
    "p.bar_label(p.containers[0])\n",
    "plt.xlabel('Number of Listings by Host')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48349abb",
   "metadata": {},
   "source": [
    "It is obvious that a vast majority of hosts have only one listing in the Chicago area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48162f2e",
   "metadata": {},
   "source": [
    "<h4>Host Response Time</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2489bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_response_time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "p = sb.countplot(x='host_response_time',data = dat)\n",
    "p.set_xticklabels(labels=p.get_xticklabels(),rotation=45)\n",
    "p.bar_label(p.containers[0])\n",
    "plt.xlabel('Host Response Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11025ef",
   "metadata": {},
   "source": [
    "Here we can see there are four categories for the response time.  Let's define a system for rating the response time by using floating numbers.  We will assign the values in hours and as follows:\n",
    " * 'within an hour' = 1 hour\n",
    " * 'within a few hours' = 5 hours\n",
    " * 'within a day' = 24 hours\n",
    " * 'a few days or more' = 48 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a39c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_response_time_float'] = dat['host_response_time'].map({'within an hour':1,'within a few hours':5,\n",
    "                                                           'within a day':24,'a few days or more':48}).astype(np.float32)\n",
    "dat['host_response_time_float'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973debc",
   "metadata": {},
   "source": [
    "<h4>Host Verifications</h4>\n",
    "\n",
    "In order to simplify future analysis, let us count the number of verifications the host has and list this in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6edec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['host_verifications'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d38643",
   "metadata": {},
   "source": [
    "We can see that the verifications are separated by a comma, so we will use this to count the number of verifications each host has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8de230",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['no_of_verif'] = dat['host_verifications'].str.count(r',') + 1\n",
    "dat.loc[:, ['host_verifications','no_of_verif']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a55e3",
   "metadata": {},
   "source": [
    "In order to catch any observations where hosts have no verifications, we will set the number of verifications to zero where the host_verifications = 'None'.  This is important since the code above would have counted 'none' and an observation without a comma (i.e. only one verification) as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba14642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['no_of_verif'] = np.where(dat['host_verifications'] == 'None', 0, dat['no_of_verif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['no_of_verif'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe69ae8",
   "metadata": {},
   "source": [
    "On average, hosts have about 5-6 different identity verifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "p = sb.countplot(x='no_of_verif',data = dat)\n",
    "p.bar_label(p.containers[0])\n",
    "plt.xlabel('Nomber of Identity Verifications by Host')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436c9ed",
   "metadata": {},
   "source": [
    "<h4>Amenities</h4>\n",
    "\n",
    "Repeat the same process for number of amenities listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['no_of_amen'] = dat['amenities'].str.count(r',') + 1\n",
    "dat.loc[:, ['amenities','no_of_amen']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7118e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['no_of_amen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed39bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "p = sb.countplot(x='no_of_amen',data = dat)\n",
    "p.set_xticklabels(labels=p.get_xticklabels(),rotation=90)\n",
    "plt.xlabel('Number of Amenities Listed by the Host')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9aafe9",
   "metadata": {},
   "source": [
    "<h4>Distance from Center of Chicago</h4>\n",
    "\n",
    "Let's calculate the distance of the listing from the center of the city of Chicago.  We will use the following coordinates: 41.8781° N, 87.6298° W (source needed?).\n",
    "\n",
    "We will use the Haversine formula to calculate the distance in miles.  In order to do so, we will first define a function to perform the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates for center of Chicago in degrees\n",
    "lat1 = 41.8781\n",
    "long1 = -87.6298\n",
    "\n",
    "# Constant, radius of the Earth in miles\n",
    "r = 3958.8\n",
    "\n",
    "# Define a function to calculate the distance\n",
    "def haversine(lat2, long2):\n",
    "    # First convert degrees into radians:\n",
    "    rlat1 = lat1 * (math.pi / 180)\n",
    "    rlat2 = lat2 * (math.pi / 180)\n",
    "    rlong1 = long1 * (math.pi / 180)\n",
    "    rlong2 = long2 * (math.pi / 180)\n",
    "    \n",
    "    # Calculate the differnce between the latitudes and longitudes\n",
    "    dlat = rlat1 - rlat2\n",
    "    dlong = rlong1 - rlong2\n",
    "    \n",
    "    # Use the Haversine formula (broken into 3 terms for simplification here)\n",
    "    a = (math.sin(dlat / 2) ** 2)         # First term\n",
    "    b = math.cos(rlat1) * math.cos(rlat2) # Second term\n",
    "    c = (math.sin(dlong / 2) ** 2)        # Third term\n",
    "    e = math.sqrt(a + b * c)\n",
    "    d = 2 * r * e                         # where r is the radius of the Earth\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66990162",
   "metadata": {},
   "source": [
    "Then, apply the formula to each observation in the data set, returning the answer in a new column for the distance from the center of the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb060ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['d_center'] = dat.apply(\n",
    "    lambda row: haversine(row['latitude'], row['longitude']),\n",
    "    axis=1)\n",
    "dat['d_center'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecde93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['d_center'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e459e",
   "metadata": {},
   "source": [
    "In order to visualize the distances, let us plot them against the listing price values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e49893",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sb.regplot(x=\"d_center\", y=\"price\", \n",
    "            line_kws={\"color\":\"r\",\"alpha\":0.5,\"lw\":3}, data=dat)\n",
    "plt.xlabel('Distance from center of city (miles)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43981d",
   "metadata": {},
   "source": [
    "On first look, it appears that the listings further from the city are less valuable on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb2868",
   "metadata": {},
   "source": [
    "<h4>Property and Room Types</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529b531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "p = sb.countplot(x='property_type',data = dat)\n",
    "p.set_xticklabels(labels=p.get_xticklabels(),rotation=90)\n",
    "plt.xlabel('Number of Amenities Listed by the Host')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "p = sb.countplot(x='room_type',data = dat)\n",
    "plt.xlabel('Room Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d461ba",
   "metadata": {},
   "source": [
    "<h2>Dimension Reduction</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc209efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45441879",
   "metadata": {},
   "source": [
    "In order to complete a Principal Component Analysis, we need to only select the numeric values and drop values with NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric values\n",
    "dat_pre_norm = dat.loc[:,['host_response_rate','host_acceptance_rate','host_is_superhost',\n",
    "                         'host_total_listings_count','host_has_profile_pic',\n",
    "                          'host_identity_verified','latitude','longitude','accommodates','bedrooms','beds',\n",
    "                         'price','minimum_minimum_nights','maximum_minimum_nights',\n",
    "                         'minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm',\n",
    "                         'maximum_nights_avg_ntm','number_of_reviews','number_of_reviews_ltm','number_of_reviews_l30d',\n",
    "                         'review_scores_rating','review_scores_accuracy','review_scores_cleanliness',\n",
    "                         'review_scores_checkin','review_scores_communication','review_scores_location',\n",
    "                         'review_scores_value','reviews_per_month']]\n",
    "dat_pre_norm = dat_pre_norm.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3112176",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_norm = scale(dat_pre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084530d",
   "metadata": {},
   "source": [
    "For the fist PCA, we will include all of the variables (i.e. columns from the selection above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=len(dat_pre_norm.columns))\n",
    "\n",
    "pca1.fit(dat_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = pca1.explained_variance_ratio_\n",
    "var1 = np.cumsum(np.round(pca1.explained_variance_ratio_, decimals=4)*100)\n",
    "print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = pd.DataFrame(var1, index=np.arange(1,int(len(dat_pre_norm.columns))+1))\n",
    "plt.plot(var1,color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aedfc2",
   "metadata": {},
   "source": [
    "Taking the first 18 principal components will correspond to 90% of the variance explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b29f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca18 = PCA(n_components=18)\n",
    "pca18.fit(dat_norm)\n",
    "data_pca18 = pca18.transform(dat_norm)\n",
    "\n",
    "# Convert the numpy array to pandas DataFrame\n",
    "data_pca18 = pd.DataFrame(data_pca18)\n",
    "data_pca18.columns = [\"PC\"+str(i) for i in range(1,19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca18.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba1484",
   "metadata": {},
   "source": [
    "From the above correlation table, we can find that the pairwise correlations between two components are close to zeros. This means that all these components are orthogonal (not correlated). There is no multicollinearity among principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eba5bc",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a3633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488485e4",
   "metadata": {},
   "source": [
    "## 1. Property Description Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca354f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a667c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = STOPWORDS\n",
    "def Mywordcloud(data, title = None):   \n",
    "    wc = WordCloud(\n",
    "    background_color = \"white\",\n",
    "    stopwords = stopwords,\n",
    "    height = 600,\n",
    "    width = 400\n",
    "    ).generate(str(data))\n",
    "    fig = plt.figure(1, figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "    plt.imshow(wc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72582796",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l4/02h672sn7w56vdlzj5gtgwzc0000gn/T/ipykernel_39733/3968385663.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMywordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dat' is not defined"
     ]
    }
   ],
   "source": [
    "Mywordcloud(dat['description'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ccd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mywordcloud(dat['neighborhood_overview'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mywordcloud(dat['host_about'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d109c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
